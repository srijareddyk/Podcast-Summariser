{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Kaggle practice set"
      ],
      "metadata": {
        "id": "0OGmD5Jailor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSEValKBOnln",
        "outputId": "d06d4272-eba9-4ee6-ca38-7b10a35de4e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydRdyS0OrIS7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VzWJO5_v02m"
      },
      "outputs": [],
      "source": [
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE-B3KOBS3iy",
        "outputId": "f4809c9c-6af3-409d-8020-5d883fd4b0ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "jZAt5YBBS4jf",
        "outputId": "f4fa8d9e-d398-404c-93f3-073a9ace37e7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/03-01-01-01-01-01-01.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-20c33929542b>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Convert audio to text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Print the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-20c33929542b>\u001b[0m in \u001b[0;36maudio_to_text\u001b[0;34m(audio_file_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Load the audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Adjust for ambient noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_for_ambient_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;31m# attempt to read the file as WAV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlittle_endian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/wave.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/wave.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# else, assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/03-01-01-01-01-01-01.wav'"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "def audio_to_text(audio_file_path):\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio file\n",
        "    with sr.AudioFile(audio_file_path) as source:\n",
        "        # Adjust for ambient noise\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "\n",
        "        # Record the audio\n",
        "        audio = recognizer.record(source)\n",
        "\n",
        "    try:\n",
        "        # Recognize speech using Google Web Speech API\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Google Web Speech API could not understand audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Google Web Speech API; {e}\")\n",
        "\n",
        "# Specify the path to your audio file\n",
        "audio_file_path = \"/content/03-01-01-01-01-01-01.wav\"\n",
        "\n",
        "# Convert audio to text\n",
        "result = audio_to_text(audio_file_path)\n",
        "\n",
        "# Print the result\n",
        "print(\"Text from audio:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX1Yz7hhU4xe"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Specify the path to your zip file\n",
        "zip_file_path = \"/content/archiveee.zip\"\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "extracted_dir = \"/content/\"\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the contents to the specified directory\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "print(f\"Contents of {zip_file_path} extracted to {extracted_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UK5MpFdV7SA"
      },
      "source": [
        "# #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0xUkVFiYnTv"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "\n",
        "def audio_to_text(audio_file_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file_path) as source:\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "        audio = recognizer.record(source)\n",
        "\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Google Web Speech API could not understand audio\")\n",
        "        return \"\"\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Google Web Speech API; {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def transcribe_audio_from_zip(zip_file_path):\n",
        "    all_text = \"\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        extracted_dir = '/content/extracted_audio_files/'\n",
        "        zip_ref.extractall(extracted_dir)\n",
        "\n",
        "    audio_files = [file for file in os.listdir(extracted_dir) if file.endswith('.wav')]\n",
        "\n",
        "    for audio_file in audio_files:\n",
        "        audio_path = os.path.join(extracted_dir, audio_file)\n",
        "        text = audio_to_text(audio_path)\n",
        "        all_text += text + \" \"\n",
        "\n",
        "    return all_text\n",
        "\n",
        "# Specify the path to your uploaded zip file\n",
        "zip_file_path = \"/content/archiveee.zip\"\n",
        "\n",
        "# Transcribe audio from the zip file\n",
        "result_text = transcribe_audio_from_zip(zip_file_path)\n",
        "\n",
        "# Print the concatenated result text\n",
        "print(\"Combined Text from Audio Files:\", result_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn1OnRujEwXp"
      },
      "outputs": [],
      "source": [
        "RAVDESS = \"/content/extracted_audio_files\"\n",
        "ravdess_dir_lis = os.listdir(RAVDESS)\n",
        "path_list = []\n",
        "gender_list = []\n",
        "emotion_list = [\n",
        "]\n",
        "emotion_dic = {\n",
        "    '03' : 'happy',\n",
        "    '01' : 'neutral',\n",
        "    '04' : 'sad',\n",
        "    '05' : 'angry',\n",
        "    '06' : 'fear',\n",
        "    '07' : 'disgust',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuDyGBtyKjm9"
      },
      "outputs": [],
      "source": [
        "ravdess_dir_lis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx-mLcbSL-98"
      },
      "outputs": [],
      "source": [
        "for directory in ravdess_dir_lis:\n",
        "    actor_files = os.listdir(os.path.join(RAVDESS, directory))\n",
        "    for audio_file in actor_files:\n",
        "        part = audio_file.split('.')[0]\n",
        "        key = part.split('-')\n",
        "        if key in emotion_dic:\n",
        "            gender_code = int(part.split('-')[6])\n",
        "            path_list.append(f\"{RAVDESS}{directory}/{audio_file}\")\n",
        "            gender_list.append('female' if gender_code & 1 == 0 else 'male')\n",
        "            emotion_list.append(emotion_dic[key])\n",
        "\n",
        "ravdess_df = pd.concat([\n",
        "    pd.DataFrame(path_list, columns=['path']),\n",
        "    pd.DataFrame(gender_list, columns=['sex']),\n",
        "    pd.DataFrame(emotion_list, columns=['emotion'])\n",
        "], axis=1)\n",
        "\n",
        "ravdess_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hURFLXcAd_ch"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEWcpRmUWEwB"
      },
      "source": [
        "# Usefull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRkjPXGPd_Sb"
      },
      "outputs": [],
      "source": [
        "for dir in ravdess_dir_lis:\n",
        "  actor_files = os.listdir(os.path.join(RAVDESS, directory))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ullU_p0eJTL"
      },
      "outputs": [],
      "source": [
        "actor_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBA7ZSYOrmKv"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "input_dir= Path(\"/content/extracted_audio_files/archive\")\n",
        "files = list(input_dir.rglob(\"*.wav*\"))\n",
        "files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ15SMRUu0Yl"
      },
      "outputs": [],
      "source": [
        "file =open('/content/mytxt.txt','w')\n",
        "for i in range(10):\n",
        "  #result.append(audio_to_text(str(i)))\n",
        "  text = audio_to_text(str(files[i]))\n",
        "  file.write(text + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJLMoXZjzpaW"
      },
      "outputs": [],
      "source": [
        "i =0\n",
        "result = audio_to_text(str(files[14]))\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHoXvJ_VS_6V"
      },
      "outputs": [],
      "source": [
        "file =open('/content/mytxt.txt','w')\n",
        "text = audio_to_text(str(files[0]))\n",
        "file.write(text)\n",
        "file.close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9Q9ORQLUa0C"
      },
      "outputs": [],
      "source": [
        "type(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM2WYNWtZiXl"
      },
      "source": [
        "#FINAL CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfi62zazF18z"
      },
      "source": [
        "speech to text model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO8NFXU5R0Xo"
      },
      "outputs": [],
      "source": [
        "! pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yecLQeu8ZkiJ"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "def audio_to_text(audio_file_path):\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio file\n",
        "    with sr.AudioFile(audio_file_path) as source:\n",
        "        # Adjust for ambient noise\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "\n",
        "        # Record the audio\n",
        "        audio = recognizer.record(source)\n",
        "\n",
        "    try:\n",
        "        # Recognize speech using Google Web Speech API\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Google Web Speech API could not understand audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Google Web Speech API; {e}\")\n",
        "\n",
        "# Specify the path to your audio file\n",
        "#audio_file_path = \"/content/audio_segment/segment_0-60.wav\"\n",
        "\n",
        "\n",
        "# Convert audio to text\n",
        "#result = audio_to_text(audio_file_path)\n",
        "\n",
        "# Print the result\n",
        "#print(\"Text from audio:\", result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou4mqSSgF4lP"
      },
      "source": [
        "zip extracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x81pL1NCZ2lz"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Specify the path to your zip file\n",
        "zip_file_path = \"/content/archiveee.zip\"\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "extracted_dir = \"/content/\"\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the contents to the specified directory\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "print(f\"Contents of {zip_file_path} extracted to {extracted_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx3JjFHnKik0"
      },
      "source": [
        "segment podcast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpT1LKNNKs3_"
      },
      "outputs": [],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmTb7zJKaBVn"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "def split_audio(input_file, output_folder, segment_duration=15):\n",
        "    # Create output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    audio = AudioSegment.from_wav(input_file)\n",
        "    audio_duration = len(audio)\n",
        "\n",
        "    for start_time in range(0, audio_duration, segment_duration * 1000):\n",
        "        end_time = min(start_time + segment_duration * 1000, audio_duration)\n",
        "        segment = audio[start_time:end_time]\n",
        "        segment_path = os.path.join(output_folder, f\"segment_{start_time//1000}-{end_time//1000}.wav\")\n",
        "        segment.export(segment_path, format=\"wav\")\n",
        "\n",
        "# Specify the path to your large audio file\n",
        "large_audio_file_path = \"/content/scotus-cotus.wav\"\n",
        "\n",
        "# Specify the output folder for segments\n",
        "output_folder = \"/content/audio_segmentsss\"\n",
        "\n",
        "# Split the audio file into segments\n",
        "split_audio(large_audio_file_path, output_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNzXCA_R60d9"
      },
      "outputs": [],
      "source": [
        "#sorting the files code\n",
        "import os\n",
        "\n",
        "# Specify the folder containing the segmented audio files\n",
        "output_folder = \"/content/audio_segments\"\n",
        "\n",
        "# Get a list of audio files in the folder\n",
        "audio_files = os.listdir(audio_folder)\n",
        "\n",
        "# Sort the audio files based on the timestamps in their filenames\n",
        "sorted_audio_files = sorted(audio_files, key=lambda x: int(x.split('_')[1].split('-')[0]))\n",
        "\n",
        "# Iterate through the sorted audio files\n",
        "for audio_file in sorted_audio_files:\n",
        "    # Process the sorted audio files as needed\n",
        "    print(audio_file)  # Replace this with your code to use the sorted files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz2ha5jDF91v"
      },
      "source": [
        "open all files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgFeTqtmaNz0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "input_dir= Path(\"/content/audio_segmentsss\")\n",
        "files = list(input_dir.rglob(\"*.wav*\"))\n",
        "files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfshIY1QKIE0"
      },
      "source": [
        "Text to speech for entire podcast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdTWTlsljEud"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "input_dir = Path(\"/content/audio_segment\")\n",
        "files = list(input_dir.rglob(\"*.wav*\"))\n",
        "\n",
        "textfile = open('/content/mytxt.txt', 'w')\n",
        "\n",
        "for i in range(len(files)):\n",
        "    text = audio_to_text(str(files[i]))\n",
        "\n",
        "    # Check if text is not None before writing to the file\n",
        "    if text is not None:\n",
        "        textfile.write(text + '\\n')\n",
        "    else:\n",
        "        print(f\"Failed to recognize speech in {str(files[i])}\")\n",
        "\n",
        "textfile.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOr3WCoeT9Rg"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Extract timestamps from filenames\n",
        "timestamps = [int(str(path.stem).split('_')[-1].split('-')[0]) for path in files]\n",
        "\n",
        "# Combine file paths and timestamps, then sort based on timestamps\n",
        "sorted_files = sorted(zip(files, timestamps), key=lambda x: x[1])\n",
        "\n",
        "# Extract only file paths from the sorted list\n",
        "sorted_file_paths = [path for path, timestamp in sorted_files]\n",
        "\n",
        "print(sorted_file_paths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjVmKw95nnwJ"
      },
      "outputs": [],
      "source": [
        "textfile = open('/content/Start-.txt', 'w')\n",
        "\n",
        "for i in range(len(sorted_file_paths)):\n",
        "    text = audio_to_text(str(sorted_file_paths[i]))\n",
        "\n",
        "    # Check if text is not None before writing to the file\n",
        "    if text is not None:\n",
        "        textfile.write(text)# + '\\n')\n",
        "    else:\n",
        "        print(f\"Failed to recognize speech in {str(sorted_file_paths[i])}\")\n",
        "\n",
        "textfile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SUMMARIZER"
      ],
      "metadata": {
        "id": "mQV9dj4YfU74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the text file into a DataFrame\n",
        "txt_file_path = \"/content/Start- (1).txt\"  # Replace with the path to your text file\n",
        "with open(txt_file_path, 'r', encoding='utf-8') as file:\n",
        "    text_content = file.read()\n",
        "\n",
        "# Create a DataFrame with a single column 'article content'\n",
        "df = pd.DataFrame({'article content': [text_content]})\n",
        "\n",
        "# Create a summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "# Function to generate a summary for each article\n",
        "def generate_summary(article):\n",
        "    # Split the article into chunks of 1000 tokens\n",
        "    max_chunk_length = 100\n",
        "    chunks = [article[i:i + max_chunk_length] for i in range(0, len(article), max_chunk_length)]\n",
        "\n",
        "    # Generate summaries for each chunk\n",
        "    summaries = [summarizer(chunk, max_length=100, min_length=10, do_sample=False)[0]['summary_text'] for chunk in chunks]\n",
        "\n",
        "    # Combine the summaries of the chunks\n",
        "    return \" \".join(summaries)\n",
        "\n",
        "# Apply the summarization function to the single article in the DataFrame\n",
        "df['Summary'] = df['article content'].apply(generate_summary)\n",
        "\n",
        "# Set pandas options to display the entire content of the 'Summary' column\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Print or save the DataFrame with the summary\n",
        "print(df[['Summary']])\n",
        "\n",
        "# Save the DataFrame with the summary to a new TXT file\n",
        "df[['Summary']].to_csv(\"/content/Start- (1).txt\", index=False, header=False, sep='\\t')"
      ],
      "metadata": {
        "id": "8ATWqnX4fUKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EVALUATION METRICS:\n",
        "\n",
        "For the evaluation part, we utilized the ROUGE (Recall-Oriented Understudy for Gisting Evaluation) package to collectively assess the quality of a system-generated summary by comparing it to a reference summary."
      ],
      "metadata": {
        "id": "uGctH4BVVowV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "\n",
        "#Read the reference summary from a file\n",
        "reference_file_path = \"/reference_summary.txt\"\n",
        "with open(reference_file_path, 'r', encoding='utf-8') as file:\n",
        "    reference_summary = file.read()\n",
        "\n",
        "#Read the system summary from a file\n",
        "system_file_path = \"/summary1.txt\"\n",
        "with open(system_file_path, 'r', encoding='utf-8') as file:\n",
        "    system_summary = file.read()\n",
        "\n",
        "#Initialize ROUGE\n",
        "rouge = Rouge()\n",
        "\n",
        "#Calculate ROUGE scores\n",
        "scores = rouge.get_scores(system_summary, reference_summary)\n",
        "\n",
        "#Print the ROUGE scores\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRjLuZNwVzDt",
        "outputId": "15b53d5b-917d-4058-87e5-9628f463dd94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "[{'rouge-1': {'r': 0.2553191489361702, 'p': 0.19933554817275748, 'f': 0.22388059209073577}, 'rouge-2': {'r': 0.05542168674698795, 'p': 0.0465587044534413, 'f': 0.050605055543816696}, 'rouge-l': {'r': 0.2425531914893617, 'p': 0.1893687707641196, 'f': 0.21268656223998952}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "TLFEjGXrXdAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DqVlQ6EUo2r",
        "outputId": "137aa5a6-b4de-43fd-9f1b-c8f7f3490d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0rYEjIySUwQp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0OGmD5Jailor",
        "_UK5MpFdV7SA",
        "LEWcpRmUWEwB"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}